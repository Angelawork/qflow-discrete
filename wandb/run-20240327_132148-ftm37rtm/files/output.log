/home/hyperpotato/anaconda3/envs/decision-transformer-gym/lib/python3.8/site-packages/wandb/sdk/lib/import_hooks.py:243: DeprecationWarning: Deprecated since Python 3.4. Use importlib.util.find_spec() instead.
  loader = importlib.find_loader(fullname, path)
/home/hyperpotato/anaconda3/envs/decision-transformer-gym/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be <class 'numpy.float32'>, actual type: float64
  logger.warn(
/home/hyperpotato/anaconda3/envs/decision-transformer-gym/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.
  logger.warn(f"{pre} is not within the observation space.")
/home/hyperpotato/anaconda3/envs/decision-transformer-gym/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be <class 'numpy.float32'>, actual type: float64
  logger.warn(
/home/hyperpotato/anaconda3/envs/decision-transformer-gym/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: [33mWARN: The obs returned by the `step()` method is not within the observation space.
  logger.warn(f"{pre} is not within the observation space.")
global_step=13, episodic_return=[10.91251]
global_step=38, episodic_return=[28.610651]
global_step=75, episodic_return=[27.435326]
global_step=102, episodic_return=[5.4052234]
global_step=113, episodic_return=[7.46734]
global_step=145, episodic_return=[26.261326]
global_step=167, episodic_return=[10.343855]
global_step=208, episodic_return=[32.33264]
global_step=223, episodic_return=[15.10476]
global_step=243, episodic_return=[21.230661]
global_step=259, episodic_return=[12.994577]
global_step=276, episodic_return=[14.5620985]
global_step=288, episodic_return=[9.228593]
global_step=329, episodic_return=[38.398487]
global_step=390, episodic_return=[67.848305]
global_step=409, episodic_return=[18.882732]
global_step=423, episodic_return=[13.0925665]
global_step=446, episodic_return=[15.711637]
global_step=465, episodic_return=[11.194533]
global_step=487, episodic_return=[13.814677]
global_step=509, episodic_return=[21.887989]
global_step=533, episodic_return=[15.6689625]
global_step=556, episodic_return=[11.10995]
global_step=570, episodic_return=[9.299522]
global_step=620, episodic_return=[31.11622]
global_step=652, episodic_return=[27.618]
global_step=671, episodic_return=[14.795697]
global_step=690, episodic_return=[15.750496]
global_step=704, episodic_return=[10.999533]
global_step=719, episodic_return=[13.189093]
global_step=739, episodic_return=[17.489927]
global_step=773, episodic_return=[18.442959]
global_step=791, episodic_return=[13.601387]
global_step=823, episodic_return=[17.120953]
global_step=846, episodic_return=[13.356247]
global_step=866, episodic_return=[16.5028]
global_step=884, episodic_return=[8.237904]
global_step=915, episodic_return=[39.05222]
global_step=926, episodic_return=[8.979667]
global_step=943, episodic_return=[8.1905155]
global_step=966, episodic_return=[10.837193]
global_step=977, episodic_return=[8.870487]
global_step=987, episodic_return=[7.7295113]
global_step=1000, episodic_return=[11.206976]
global_step=1036, episodic_return=[45.082954]
global_step=1049, episodic_return=[11.473378]
global_step=1058, episodic_return=[4.7519517]
global_step=1077, episodic_return=[15.602547]
global_step=1091, episodic_return=[8.455522]
global_step=1104, episodic_return=[12.269443]
global_step=1115, episodic_return=[9.612757]
global_step=1144, episodic_return=[20.746592]
global_step=1201, episodic_return=[59.124107]
global_step=1214, episodic_return=[10.652263]
global_step=1228, episodic_return=[11.45295]
global_step=1245, episodic_return=[13.224719]
global_step=1263, episodic_return=[11.752099]
global_step=1281, episodic_return=[13.502222]
global_step=1305, episodic_return=[24.383574]
global_step=1318, episodic_return=[11.789735]
global_step=1340, episodic_return=[11.46562]
global_step=1356, episodic_return=[10.15149]
global_step=1379, episodic_return=[30.881079]
global_step=1408, episodic_return=[10.404765]
global_step=1421, episodic_return=[11.67607]
global_step=1437, episodic_return=[9.8462305]
global_step=1452, episodic_return=[10.705885]
global_step=1470, episodic_return=[12.545941]
global_step=1494, episodic_return=[25.496634]
global_step=1531, episodic_return=[37.68815]
global_step=1542, episodic_return=[8.132014]
global_step=1558, episodic_return=[13.123883]
global_step=1578, episodic_return=[23.579687]
global_step=1604, episodic_return=[8.900353]
global_step=1624, episodic_return=[14.904622]
global_step=1643, episodic_return=[15.201219]
global_step=1664, episodic_return=[19.18242]
global_step=1690, episodic_return=[21.69039]
global_step=1728, episodic_return=[53.393856]
global_step=1745, episodic_return=[12.643121]
global_step=1798, episodic_return=[61.788296]
global_step=1812, episodic_return=[10.778318]
global_step=1828, episodic_return=[12.275214]
global_step=1844, episodic_return=[14.714555]
global_step=1858, episodic_return=[11.176002]
global_step=1879, episodic_return=[16.4808]
global_step=1902, episodic_return=[24.602652]
global_step=1978, episodic_return=[113.35282]
global_step=1999, episodic_return=[15.376908]
global_step=2033, episodic_return=[34.736435]
global_step=2105, episodic_return=[119.10404]
global_step=2116, episodic_return=[6.652383]
global_step=2144, episodic_return=[11.797904]
global_step=2212, episodic_return=[76.420784]
global_step=2227, episodic_return=[13.876787]
global_step=2249, episodic_return=[16.38469]
global_step=2270, episodic_return=[11.320691]
global_step=2297, episodic_return=[17.013807]
global_step=2319, episodic_return=[21.21184]
global_step=2329, episodic_return=[8.336202]
global_step=2339, episodic_return=[7.332041]
global_step=2362, episodic_return=[10.807482]
global_step=2374, episodic_return=[7.0916667]
global_step=2394, episodic_return=[17.686611]
global_step=2426, episodic_return=[33.148933]
global_step=2444, episodic_return=[18.563692]
global_step=2474, episodic_return=[28.454365]
global_step=2488, episodic_return=[9.844374]
global_step=2527, episodic_return=[44.57848]
global_step=2545, episodic_return=[14.623961]
global_step=2575, episodic_return=[6.7078133]
global_step=2594, episodic_return=[16.392813]
global_step=2611, episodic_return=[13.573701]
global_step=2637, episodic_return=[24.403244]
global_step=2658, episodic_return=[20.776846]
global_step=2708, episodic_return=[46.932655]
global_step=2775, episodic_return=[66.10659]
global_step=2826, episodic_return=[42.320164]
global_step=2839, episodic_return=[10.690672]
global_step=2886, episodic_return=[67.08224]
global_step=2900, episodic_return=[10.959874]
global_step=2913, episodic_return=[9.483068]
global_step=2930, episodic_return=[14.106655]
global_step=2983, episodic_return=[50.136776]
global_step=3029, episodic_return=[53.95163]
global_step=3047, episodic_return=[13.22739]
global_step=3065, episodic_return=[6.9301405]
global_step=3080, episodic_return=[9.377669]
global_step=3100, episodic_return=[15.975491]
global_step=3121, episodic_return=[16.265923]
global_step=3131, episodic_return=[6.278533]
global_step=3144, episodic_return=[11.356188]
global_step=3175, episodic_return=[39.457504]
global_step=3200, episodic_return=[10.770419]
global_step=3233, episodic_return=[22.232012]
global_step=3251, episodic_return=[12.317321]
global_step=3286, episodic_return=[35.494564]
global_step=3301, episodic_return=[10.98957]
global_step=3313, episodic_return=[8.219004]
global_step=3323, episodic_return=[6.291406]
global_step=3349, episodic_return=[10.118257]
global_step=3394, episodic_return=[63.352005]
global_step=3412, episodic_return=[17.540083]
global_step=3437, episodic_return=[21.849709]
global_step=3452, episodic_return=[10.542076]
global_step=3485, episodic_return=[19.856411]
global_step=3503, episodic_return=[15.6243]
global_step=3536, episodic_return=[46.772476]
global_step=3567, episodic_return=[18.835161]
global_step=3600, episodic_return=[27.15684]
global_step=3613, episodic_return=[10.762612]
global_step=3627, episodic_return=[10.579194]
global_step=3640, episodic_return=[11.274772]
global_step=3660, episodic_return=[14.687841]
global_step=3675, episodic_return=[12.755835]
global_step=3695, episodic_return=[13.435434]
global_step=3712, episodic_return=[8.441327]
global_step=3735, episodic_return=[8.015493]
global_step=3767, episodic_return=[16.321404]
global_step=3807, episodic_return=[45.876957]
global_step=3820, episodic_return=[12.363773]
global_step=3834, episodic_return=[7.215132]
global_step=3844, episodic_return=[7.6343102]
global_step=3886, episodic_return=[39.016968]
global_step=3895, episodic_return=[6.8335023]
global_step=3956, episodic_return=[46.633724]
global_step=3981, episodic_return=[14.114166]
global_step=3997, episodic_return=[17.027565]
global_step=4024, episodic_return=[23.346865]
global_step=4039, episodic_return=[8.068167]
global_step=4055, episodic_return=[12.842094]
global_step=4067, episodic_return=[9.050424]
global_step=4090, episodic_return=[14.300549]
global_step=4102, episodic_return=[8.155021]
global_step=4113, episodic_return=[8.280169]
global_step=4123, episodic_return=[7.093677]
global_step=4145, episodic_return=[22.305061]
global_step=4159, episodic_return=[9.3989525]
global_step=4181, episodic_return=[22.342348]
global_step=4198, episodic_return=[17.79197]
global_step=4256, episodic_return=[72.745766]
global_step=4270, episodic_return=[10.891333]
global_step=4278, episodic_return=[5.880494]
global_step=4296, episodic_return=[7.397458]
global_step=4311, episodic_return=[11.540014]
global_step=4326, episodic_return=[10.808572]
global_step=4345, episodic_return=[16.543728]
global_step=4358, episodic_return=[6.6332107]
global_step=4370, episodic_return=[11.306983]
global_step=4383, episodic_return=[9.501624]
global_step=4418, episodic_return=[33.392166]
global_step=4432, episodic_return=[12.539321]
global_step=4462, episodic_return=[28.61213]
global_step=4483, episodic_return=[15.894131]
global_step=4518, episodic_return=[25.176218]
global_step=4527, episodic_return=[6.787283]
global_step=4557, episodic_return=[25.36848]
global_step=4568, episodic_return=[6.606761]
global_step=4580, episodic_return=[8.895657]
global_step=4594, episodic_return=[8.926193]
global_step=4628, episodic_return=[29.960464]
global_step=4640, episodic_return=[10.355267]
global_step=4663, episodic_return=[17.11729]
global_step=4689, episodic_return=[22.127869]
global_step=4700, episodic_return=[8.12369]
global_step=4711, episodic_return=[7.4351897]
qflow_discrete.py:190: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  q_loss = F.mse_loss(q1, target) + F.mse_loss(q2, target)
global_step=4734, episodic_return=[6.849504]
global_step=4754, episodic_return=[11.249021]
global_step=4764, episodic_return=[8.186752]
global_step=4784, episodic_return=[17.18664]
global_step=4808, episodic_return=[12.495514]
global_step=4824, episodic_return=[12.993621]
global_step=4849, episodic_return=[17.962973]
global_step=4860, episodic_return=[7.9686112]
global_step=4907, episodic_return=[48.710648]
global_step=4927, episodic_return=[14.221926]
global_step=4948, episodic_return=[21.101183]
global_step=4969, episodic_return=[18.61413]
global_step=4991, episodic_return=[16.83693]
global_step=5008, episodic_return=[14.758469]
global_step=5028, episodic_return=[11.29915]
global_step=5041, episodic_return=[9.703569]
global_step=5069, episodic_return=[16.727526]
global_step=5092, episodic_return=[11.426746]
global_step=5104, episodic_return=[10.311889]
global_step=5131, episodic_return=[15.138827]
global_step=5158, episodic_return=[8.765991]
global_step=5172, episodic_return=[8.923352]
global_step=5187, episodic_return=[12.358428]
global_step=5217, episodic_return=[30.294207]
global_step=5251, episodic_return=[35.21508]
global_step=5270, episodic_return=[14.864763]
global_step=5296, episodic_return=[27.459738]
global_step=5317, episodic_return=[14.125759]
global_step=5333, episodic_return=[12.210277]
global_step=5370, episodic_return=[47.514366]
global_step=5416, episodic_return=[69.10497]
global_step=5436, episodic_return=[16.954128]
global_step=5449, episodic_return=[11.466726]
global_step=5475, episodic_return=[11.140919]
global_step=5491, episodic_return=[14.481881]
global_step=5533, episodic_return=[9.512188]
global_step=5554, episodic_return=[16.241272]
global_step=5614, episodic_return=[59.79507]
global_step=5629, episodic_return=[11.097006]
global_step=5656, episodic_return=[17.011215]
global_step=5685, episodic_return=[21.928926]
global_step=5724, episodic_return=[47.42479]
global_step=5747, episodic_return=[15.598812]
global_step=5764, episodic_return=[14.798149]
global_step=5783, episodic_return=[16.802458]
global_step=5791, episodic_return=[5.710171]
global_step=5815, episodic_return=[11.196119]
global_step=5824, episodic_return=[7.414137]
global_step=5854, episodic_return=[21.950281]
global_step=5883, episodic_return=[12.747638]
global_step=5904, episodic_return=[9.946182]
global_step=5918, episodic_return=[13.0374775]
global_step=5943, episodic_return=[20.283577]
global_step=5971, episodic_return=[20.890217]
global_step=5987, episodic_return=[15.475517]
global_step=6043, episodic_return=[87.46538]
global_step=6063, episodic_return=[20.457191]
global_step=6098, episodic_return=[33.39701]
global_step=6121, episodic_return=[5.548757]
global_step=6141, episodic_return=[10.556331]
global_step=6161, episodic_return=[15.854909]
global_step=6176, episodic_return=[11.241048]
global_step=6213, episodic_return=[37.428112]
global_step=6228, episodic_return=[9.86444]
global_step=6239, episodic_return=[9.626989]
global_step=6267, episodic_return=[14.143679]
global_step=6279, episodic_return=[9.303654]
global_step=6306, episodic_return=[33.01844]
global_step=6323, episodic_return=[14.432035]
global_step=6336, episodic_return=[9.941944]
global_step=6403, episodic_return=[130.14891]
global_step=6435, episodic_return=[10.254613]
global_step=6463, episodic_return=[20.435612]
global_step=6483, episodic_return=[14.607312]
global_step=6509, episodic_return=[23.76792]
global_step=6523, episodic_return=[11.696175]
global_step=6539, episodic_return=[16.049038]
global_step=6566, episodic_return=[13.672946]
global_step=6586, episodic_return=[14.134585]
global_step=6606, episodic_return=[13.809307]
global_step=6632, episodic_return=[18.517794]
global_step=6654, episodic_return=[20.16041]
global_step=6692, episodic_return=[9.010206]
global_step=6718, episodic_return=[11.594166]
global_step=6738, episodic_return=[19.928738]
global_step=6748, episodic_return=[6.372292]
global_step=6768, episodic_return=[22.465769]
global_step=6780, episodic_return=[6.270695]
global_step=6861, episodic_return=[87.88177]
global_step=6872, episodic_return=[8.867343]
global_step=6901, episodic_return=[37.30883]
global_step=6918, episodic_return=[11.213813]
global_step=6929, episodic_return=[7.3242]
global_step=6946, episodic_return=[14.224705]
global_step=7015, episodic_return=[111.05951]
global_step=7027, episodic_return=[10.584097]
global_step=7055, episodic_return=[22.365936]
global_step=7069, episodic_return=[12.839843]
global_step=7091, episodic_return=[18.318205]
global_step=7108, episodic_return=[12.837487]
global_step=7132, episodic_return=[25.166536]
global_step=7157, episodic_return=[22.029243]
global_step=7175, episodic_return=[18.53456]
global_step=7190, episodic_return=[13.796798]
global_step=7206, episodic_return=[12.667707]
global_step=7217, episodic_return=[8.236434]
global_step=7229, episodic_return=[9.753451]
global_step=7254, episodic_return=[13.592586]
global_step=7274, episodic_return=[13.045968]
global_step=7299, episodic_return=[22.578812]
global_step=7355, episodic_return=[32.84186]
global_step=7385, episodic_return=[19.52045]
global_step=7409, episodic_return=[14.064782]
global_step=7441, episodic_return=[19.361063]
global_step=7460, episodic_return=[15.621062]
global_step=7473, episodic_return=[11.637313]
global_step=7490, episodic_return=[14.984785]
global_step=7502, episodic_return=[6.893022]
global_step=7521, episodic_return=[19.852518]
global_step=7533, episodic_return=[10.414468]
global_step=7556, episodic_return=[16.377714]
global_step=7572, episodic_return=[14.406674]
global_step=7595, episodic_return=[11.476752]
global_step=7611, episodic_return=[7.7371364]
global_step=7633, episodic_return=[13.558225]
global_step=7663, episodic_return=[9.193155]
global_step=7710, episodic_return=[34.46036]
global_step=7759, episodic_return=[41.04296]
global_step=7777, episodic_return=[11.728763]
global_step=7821, episodic_return=[29.19536]
global_step=7834, episodic_return=[10.78449]
global_step=7879, episodic_return=[39.849792]
global_step=7905, episodic_return=[20.85258]
global_step=7930, episodic_return=[30.432396]
global_step=7943, episodic_return=[10.466048]
global_step=7968, episodic_return=[11.117947]
global_step=7989, episodic_return=[8.297329]
global_step=8012, episodic_return=[14.355796]
global_step=8031, episodic_return=[10.331087]
global_step=8060, episodic_return=[16.560009]
global_step=8075, episodic_return=[9.685336]
global_step=8095, episodic_return=[21.17819]
global_step=8111, episodic_return=[8.312008]
global_step=8126, episodic_return=[14.362661]
global_step=8139, episodic_return=[5.299162]
global_step=8171, episodic_return=[28.073027]
global_step=8189, episodic_return=[19.312288]
global_step=8209, episodic_return=[11.901637]
global_step=8237, episodic_return=[14.380264]
global_step=8250, episodic_return=[11.331094]
global_step=8271, episodic_return=[16.321619]
global_step=8310, episodic_return=[49.886543]
global_step=8328, episodic_return=[14.518579]
global_step=8340, episodic_return=[6.9923525]
global_step=8364, episodic_return=[21.638031]
global_step=8377, episodic_return=[8.247801]
global_step=8391, episodic_return=[12.672686]
global_step=8420, episodic_return=[16.241528]
global_step=8461, episodic_return=[36.875576]
global_step=8474, episodic_return=[10.815763]
global_step=8489, episodic_return=[15.638237]
global_step=8499, episodic_return=[8.2660885]
global_step=8516, episodic_return=[14.22884]
global_step=8534, episodic_return=[6.6708446]
global_step=8550, episodic_return=[16.320839]
global_step=8569, episodic_return=[18.00868]
global_step=8587, episodic_return=[11.762662]
global_step=8598, episodic_return=[8.626814]
global_step=8612, episodic_return=[8.257145]
global_step=8653, episodic_return=[56.499176]
global_step=8667, episodic_return=[9.848671]
global_step=8678, episodic_return=[9.019869]
global_step=8705, episodic_return=[17.195124]
global_step=8719, episodic_return=[9.515593]
global_step=8729, episodic_return=[7.8720484]
global_step=8751, episodic_return=[18.97466]
global_step=8771, episodic_return=[19.66067]
global_step=8789, episodic_return=[18.47869]
global_step=8811, episodic_return=[21.070969]
global_step=8825, episodic_return=[9.588201]
global_step=8860, episodic_return=[12.243275]
global_step=8883, episodic_return=[17.198498]
global_step=8903, episodic_return=[5.404364]
global_step=8919, episodic_return=[7.3588877]
global_step=8932, episodic_return=[7.2767286]
global_step=8977, episodic_return=[27.120174]
global_step=9003, episodic_return=[21.286507]
global_step=9039, episodic_return=[60.068718]
global_step=9050, episodic_return=[7.98124]
global_step=9140, episodic_return=[79.80805]
global_step=9178, episodic_return=[32.60986]
global_step=9199, episodic_return=[22.349852]
global_step=9224, episodic_return=[28.217682]
global_step=9234, episodic_return=[7.926721]
global_step=9283, episodic_return=[47.4056]
global_step=9297, episodic_return=[8.269029]
global_step=9313, episodic_return=[10.798233]
global_step=9331, episodic_return=[15.152088]
global_step=9350, episodic_return=[13.898699]
global_step=9369, episodic_return=[17.248865]
global_step=9379, episodic_return=[7.0661826]
global_step=9426, episodic_return=[41.827896]
global_step=9447, episodic_return=[9.334501]
global_step=9465, episodic_return=[16.19705]
global_step=9477, episodic_return=[5.6932507]
global_step=9525, episodic_return=[75.69884]
global_step=9535, episodic_return=[6.6720443]
global_step=9551, episodic_return=[14.926572]
global_step=9563, episodic_return=[10.17401]
global_step=9583, episodic_return=[10.526222]
global_step=9605, episodic_return=[12.03748]
global_step=9631, episodic_return=[34.086052]
global_step=9654, episodic_return=[11.382544]
global_step=9682, episodic_return=[24.499634]
global_step=9696, episodic_return=[11.004256]
global_step=9710, episodic_return=[12.600416]
global_step=9731, episodic_return=[22.081722]
global_step=9741, episodic_return=[8.728828]
global_step=9762, episodic_return=[16.82171]
global_step=9777, episodic_return=[10.254854]
global_step=9802, episodic_return=[16.397419]
global_step=9811, episodic_return=[7.397029]
global_step=9826, episodic_return=[11.886522]
global_step=9839, episodic_return=[10.515117]
global_step=9857, episodic_return=[9.482174]
global_step=9865, episodic_return=[5.8545027]
global_step=9878, episodic_return=[11.438873]
global_step=9890, episodic_return=[9.3678]
global_step=9913, episodic_return=[23.651533]
global_step=9948, episodic_return=[44.415894]
global_step=9967, episodic_return=[16.868868]
global_step=9979, episodic_return=[7.7154875]
global_step=10000, episodic_return=[15.374155]
global_step=10019, episodic_return=[9.439463]
global_step=10036, episodic_return=[9.362227]
global_step=10066, episodic_return=[18.58617]
global_step=10076, episodic_return=[7.7122765]
global_step=10095, episodic_return=[18.533073]
global_step=10110, episodic_return=[6.3213353]
global_step=10125, episodic_return=[7.327277]
global_step=10153, episodic_return=[9.9826355]
global_step=10186, episodic_return=[22.397156]
global_step=10218, episodic_return=[20.20153]
global_step=10245, episodic_return=[11.101572]
global_step=10264, episodic_return=[12.479584]
global_step=10275, episodic_return=[8.996296]
global_step=10290, episodic_return=[14.038334]
global_step=10304, episodic_return=[9.687688]
Traceback (most recent call last):
  File "qflow_discrete.py", line 183, in <module>
    next_actions, logp = gflownet(data.next_observations)
  File "/home/hyperpotato/anaconda3/envs/decision-transformer-gym/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/hyperpotato/anaconda3/envs/decision-transformer-gym/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hyperpotato/qflow-discrete/qflow_model.py", line 138, in forward
    a_i = dist.sample().unsqueeze(1)
  File "/home/hyperpotato/anaconda3/envs/decision-transformer-gym/lib/python3.8/site-packages/torch/distributions/categorical.py", line 132, in sample
    samples_2d = torch.multinomial(probs_2d, sample_shape.numel(), True).T
KeyboardInterrupt